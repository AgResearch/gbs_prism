#!/bin/env pypy
from __future__ import print_function
import itertools
import sys
import argparse
import re
import os

# simple fasta iter
def fasta_iter(filestream):
    record_iter = (record.strip() for record in filestream if len(record.strip()) > 0)
    seq_group_iter = itertools.groupby(record_iter, lambda record:{True:"name", False:"seq"}[record[0] == ">"])
    name = None
    for (group, records) in seq_group_iter:
        if group == "name":
            name=records.next().split()[0][1:]
        else:
            yield (name, list(itertools.chain((name,),records)))


def augment_hmc(filename, options):
    if options["method"] == "dup_all":
                
        with open(filename,"r") as hmcstream:
            
            record_count = 0
            for record in hmcstream:

                fields=re.split("\s+", record.strip())

                samples_start_index = 1
                samples_end_index = len(fields) - 5
                totals_start_index = samples_end_index
                totals_end_index = len(fields)-1

                out_record = fields[0:samples_end_index]

                # if this is the first record it is a heading, so output adjusted headings 

                if record_count == 0:
                    for i in range(0,options["dupe_count"]):
                        for j in range(samples_start_index, samples_end_index):
                            out_record.append("FAKE%d%s"%(i+1, fields[j]))

                    for j in range(totals_start_index, totals_end_index):
                        out_record.append(fields[j])
                                              

                    out_record.append(fields[totals_end_index])

                    print("\t".join(out_record))
                else:
                    for i in range(0,options["dupe_count"]):
                        for j in range(samples_start_index, samples_end_index):
                            out_record.append(fields[j])

                    for j in range(totals_start_index, totals_end_index):
                        out_record.append(str((1+options["dupe_count"]) *  int(fields[j])))
                                              

                    out_record.append(fields[totals_end_index])

                    print("\t".join(out_record))
                    
                record_count += 1

    else:
        raise Exception("unsupported augment method %(method)s"%args)
                    

                
def get_options():
    description = """
this script takes one of the files generated by tassel such as /dataset/2024_illumina_sequencing_e/scratch/postprocessing/gbs/230901_A01439_0210_AHL5HCDRX3/SQ2220.all.fallow_deer.PstI/hapMap/HapMap.hmc.txt and
duplicates all of the samples twice , witgh a fake name, and adjusts the totals columns. It is mainly intended to allow analysis and reporting of singleton samples in the usual way.

Example :

iramohio-01$ head -3 /dataset/2024_illumina_sequencing_e/scratch/postprocessing/gbs/230901_A01439_0210_AHL5HCDRX3/SQ2220.all.fallow_deer.PstI/hapMap/HapMap.hmc.txt
rs      qc1021959-1_HL5HCDRX3_1_2220_X4 qc1021959-1_HL5HCDRX3_2_2220_X4 HetCount_allele1        HetCount_allele2        Count_allele1   Count_allele2   Frequency
TP1     3|1     2|4     5       5       5       5       0.500
TP2     2|4     6|1     8       5       8       5       0.615

these records become


rs      qc1021959-1_HL5HCDRX3_1_2220_X4 qc1021959-1_HL5HCDRX3_2_2220_X4 HetCount_allele1    FAKE1qc1021959-1_HL5HCDRX3_1_2220_X4 FAKE1qc1021959-1_HL5HCDRX3_2_2220_X4 FAKE2HetCount_allele1 qc1021959-1_HL5HCDRX3_1_2220_X4 FAKE2qc1021959-1_HL5HCDRX3_2_2220_X4 HetCount_allele1     HetCount_allele2        Count_allele1   Count_allele2   Frequency
TP1     3|1     2|4     3|1     2|4    3|1     2|4     15       15      15       15       0.500
TP2     2|4     6|1     2|4     6|1    2|4     6|1     24       15      24       15       0.615


rs      qc1021959-1_HL5HCDRX3_1_2220_X4 qc1021959-1_HL5HCDRX3_2_2220_X4 FAKE1qc1021959-1_HL5HCDRX3_1_2220_X4    FAKE1qc1021959-1_HL5HCDRX3_2_2220_X4    FAKE2qc1021959-1_HL5HCDRX3_1_2220_X4    FAKE2qc1021959-1_HL5HCDRX3_2_2220_X4    HetCount_allele1     HetCount_allele2        Count_allele1   Count_allele2   Frequency
TP1     3|1     2|4     3|1     2|4     3|1     2|4     55      55      55      55      0.500
TP2     2|4     6|1     2|4     6|1     2|4     6|1     88      55      88      55      0.615
TP3     3|15    2|14    3|15    2|14    3|15    2|14    55      2929    55      2929    0.147
TP4     4|7     4|7     4|7     4|7     4|7     4|7     88      1414    88      1414    0.364


    """

    long_description = """
    Example :

augment_singleton_hapmap.py  /dataset/2024_illumina_sequencing_e/scratch/postprocessing/gbs/230901_A01439_0210_AHL5HCDRX3/SQ2220.all.fallow_deer.PstI/hapMap/HapMap.hmc.txt 

    """
    parser = argparse.ArgumentParser(description=description, epilog=long_description, formatter_class = argparse.RawDescriptionHelpFormatter)
    parser.add_argument('files', type=str, nargs='*',help='space-seperated list of files to process')
    parser.add_argument('-m', '--method', dest='method', type=str, default = 'dup_all' , choices = ['dup_all'] , help="augmentation_method")
    parser.add_argument('-d', '--dupe_count', dest='dupe_count', type=int, default = 2 , help="number of dupes to insert")
    parser.add_argument('-t', '--task', dest='task', type=str, default = 'augment_hmc' , choices = ['augment_hmc'], help="task")    
    
    
    args = vars(parser.parse_args())

    return args


def main():

    args=get_options()
    for filetodo in args["files"]:
        if not os.path.exists(filetodo):
            print("augment_singleton_hapmap : %s does not exist so ignoring) "%filetodo)
            continue

        if args["task"] == "augment_hmc": 
            augment_hmc(filetodo, args)
        else:
            raise Exception("unsupported task %(task)s"%args)
        

if __name__ == "__main__":
   main()

